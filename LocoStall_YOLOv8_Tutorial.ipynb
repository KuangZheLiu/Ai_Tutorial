{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KuangZheLiu/Ai_Tutorial/blob/main/LocoStall_YOLOv8_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install YOLO pack\n",
        "\n",
        "- https://github.com/ultralytics/ultralytics/blob/main/requirements.txt\n"
      ],
      "metadata": {
        "id": "e5jV5YwmorHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcFbhrh2HjvD"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "#### Download - gdown - https://github.com/wkentaro/gdown\n",
        "\n",
        "## Download Dataset From GoogleDrive\n",
        "### !gdown --fuzzy '{downlad-link-id}' -O {filename.zip}\n",
        "\n",
        "## Download Dataset From Github\n",
        "### !git clone"
      ],
      "metadata": {
        "id": "NsVHBo6JpORp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "!pip install --upgrade gdown\n",
        "# -O output\n",
        "!gdown --fuzzy '1smuV4GC2miH-mfsiEVWkZZICEaIFQ3X0' -O datasets.zip\n",
        "\n",
        "# Datasets_Tutorial.zip\n",
        "# https://drive.google.com/file/d/1smuV4GC2miH-mfsiEVWkZZICEaIFQ3X0/view?usp=sharing"
      ],
      "metadata": {
        "id": "i8gEZ-VMH4GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from urllib.request import urlretrieve\n",
        "# url = \"https://github.com/-\"\n",
        "# urlretrieve(url, \"datasets.zip\")"
      ],
      "metadata": {
        "id": "MBdFSSnS8CtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset\n",
        "!unzip -q datasets.zip"
      ],
      "metadata": {
        "id": "oxhqiUfFKS8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Check\n",
        "from glob import glob\n",
        "\n",
        "img_train = sorted(glob('/content/datasets/train/images/*.jpg'))\n",
        "img_val = sorted(glob('/content/datasets/valid/images/*.jpg'))\n",
        "img_test = sorted(glob('/content/datasets/test/images/*.jpg'))\n",
        "\n",
        "print(len(img_train), len(img_val), len(img_test))"
      ],
      "metadata": {
        "id": "h-2pFxwR8LBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model and weight\n",
        "\n",
        "- https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v8/yolov8.yaml\n",
        "\n",
        "- https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/__init__.py\n",
        "\n",
        "- https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml\n"
      ],
      "metadata": {
        "id": "IkAU_JdBsDqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a model weight\n",
        "!gdown --fuzzy '1YzbGLJZc6c8WAzJsbml_7cciKzY8f7TR' -O best.pt\n",
        "\n",
        "# LocoStall_Model_YOLOv8m_final_0816\n",
        "# https://drive.google.com/file/d/1YzbGLJZc6c8WAzJsbml_7cciKzY8f7TR/view?usp=drive_link"
      ],
      "metadata": {
        "id": "j83z0tgQl-sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "\n",
        "# model = YOLO('yolov8m.yaml')  # build a new model from YAML\n",
        "# model = YOLO('yolov8m.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "model = YOLO('yolov8m.yaml').load('yolov8m.pt')  # build from YAML and transfer weights\n",
        "# model = YOLO('yolov8m.yaml').load('best.pt')\n"
      ],
      "metadata": {
        "id": "jP556VxBHtFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a2dcfe-2051-4166-82b0-85b3d1a58477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n",
            "YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt to 'yolov8m.pt'...\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 77.3MB/s]\n",
            "Transferred 475/475 items from pretrained weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "# data: 相對dataset路徑\n",
        "# save_period=3, project='LocaStall_YOLO_Model', name='Tutorial'\n",
        "model.train(data=\"datasets/shop.yaml\", epochs=50, patience=5,)  # train the model"
      ],
      "metadata": {
        "id": "BVQ4Dn7iJOav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ac91f9-8046-48b6-e703-98b24cbace13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.157 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=datasets/shop.yaml, epochs=5, patience=5, batch=16, imgsz=640, save=True, save_period=3, cache=False, device=None, workers=8, project=LocaStall_YOLO_Model, name=8m_300img_ori, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=LocaStall_YOLO_Model/8m_300img_ori\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n",
            "YOLOv8m summary: 295 layers, 25862110 parameters, 25862094 gradients\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir LocaStall_YOLO_Model/8m_300img_ori', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/train/labels.cache... 960 images, 2 backgrounds, 40 corrupt: 100%|██████████| 1000/1000 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0628_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0628_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0629_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0629_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0634_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0634_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0635_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0635_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0637_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0637_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0638_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0638_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0639_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0639_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0644_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0644_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0645_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0645_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0647_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0647_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0650_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0650_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0782_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0782_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0783_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0783_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0784_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0784_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0785_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0785_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0786_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0786_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0789_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0789_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0790_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0790_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0791_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0791_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0792_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0792_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0793_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0793_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0794_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0794_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0797_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0797_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0798_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0798_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0799_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0799_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0800_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0800_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0801_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0801_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0802_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0802_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_0999_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_0999_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1001_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1001_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1002_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1002_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1003_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1003_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1004_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1004_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1005_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1005_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1008_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1008_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1009_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1009_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1010_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1010_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1011_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1011_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1012_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1012_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/IMG_1013_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/train/images/IMG_1013_urik.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/MaruYaki_167.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PXL_20230707_100716156_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PXL_20230707_110450760_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PXL_20230707_110451717_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PXL_20230707_110453043_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PXL_20230707_114337070_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PXL_20230707_114338674_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PXL_20230707_114339915_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PepperBun_19.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PepperBun_227.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/train/images/PepperBun_241.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/valid/labels.cache... 360 images, 0 backgrounds, 15 corrupt: 100%|██████████| 375/375 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0632_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0632_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0633_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0633_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0640_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0640_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0641_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0641_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0648_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0648_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0649_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0649_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0787_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0787_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0788_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0788_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0795_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0795_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0796_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0796_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0997_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0997_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_0998_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_0998_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_1006_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_1006_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_1007_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_1007_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/IMG_1014_urik.jpg: ignoring corrupt image/label: cannot identify image file '/content/datasets/valid/images/IMG_1014_urik.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/PXL_20230707_100722883_erin.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/datasets/valid/images/PXL_20230707_100724782_erin.jpg: corrupt JPEG restored and saved\n",
            "Plotting labels to LocaStall_YOLO_Model/8m_300img_ori/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mLocaStall_YOLO_Model/8m_300img_ori\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/5      6.94G      1.297      2.295      1.474         57        640: 100%|██████████| 60/60 [01:33<00:00,  1.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:21<00:00,  1.77s/it]\n",
            "                   all        360        526      0.806       0.82      0.884      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/5      7.08G      1.074      1.014      1.268         54        640: 100%|██████████| 60/60 [01:45<00:00,  1.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:20<00:00,  1.74s/it]\n",
            "                   all        360        526      0.766      0.731      0.764      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/5      7.07G      1.031       0.84      1.246         45        640: 100%|██████████| 60/60 [01:49<00:00,  1.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:20<00:00,  1.72s/it]\n",
            "                   all        360        526      0.906      0.888      0.947      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        4/5      7.11G     0.9961     0.7502      1.255         50        640: 100%|██████████| 60/60 [01:37<00:00,  1.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:18<00:00,  1.52s/it]\n",
            "                   all        360        526      0.909      0.956      0.964      0.718\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        5/5      7.11G     0.9709     0.6834      1.221         63        640: 100%|██████████| 60/60 [01:40<00:00,  1.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:24<00:00,  2.02s/it]\n",
            "                   all        360        526      0.916      0.937      0.977      0.729\n",
            "\n",
            "5 epochs completed in 0.191 hours.\n",
            "Optimizer stripped from LocaStall_YOLO_Model/8m_300img_ori/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from LocaStall_YOLO_Model/8m_300img_ori/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating LocaStall_YOLO_Model/8m_300img_ori/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.157 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8m summary (fused): 218 layers, 25845550 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:32<00:00,  2.68s/it]\n",
            "                   all        360        526      0.915      0.937      0.977      0.729\n",
            "             PepperBun        360        126      0.928      0.881      0.973      0.693\n",
            "             SpicyTofu        360         75       0.96      0.973      0.984      0.776\n",
            "            PigKnuckle        360         73      0.808      0.986      0.978      0.788\n",
            "                 Machi        360        102      0.971      0.972      0.993      0.789\n",
            "              MaruYaki        360        150       0.91      0.872      0.957      0.598\n",
            "Speed: 0.2ms preprocess, 7.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mLocaStall_YOLO_Model/8m_300img_ori\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ],
      "metadata": {
        "id": "WiCok6YyLDHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the validation set\n",
        "metrics = model.val()\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "qyCv1VesJXrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation with test images"
      ],
      "metadata": {
        "id": "ynpuuzw4LjJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the test data set\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import cv2\n",
        "# Image.open():RGB，cv2.imread():BGR\n",
        "\n",
        "# Load Model Weight\n",
        "model = YOLO(\"/content/best.pt\")\n",
        "\n",
        "# paths_img = sorted(glob('/content/datasets/test/images/*'))\n",
        "# from PIL\n",
        "for i in range(0, len(img_test)):\n",
        "  img = Image.open(img_test[i])\n",
        "  results = model.predict(source=img, save=True, conf=0.4)\n",
        "\n",
        "# result = results[0]\n",
        "# print(\"Box len:\", len(result.boxes))\n",
        "# box = result.boxes[0]\n",
        "# print(\"Object type:\", box.cls[0])\n",
        "# print(\"Coordinates:\", box.xyxy)\n",
        "# print(\"Probability:\", box.conf[0])"
      ],
      "metadata": {
        "id": "H_7Qi8Vm5uh6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}